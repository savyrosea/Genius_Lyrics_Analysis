{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from collections import Counter\n",
    "from random import randrange\n",
    "from profanity_check import predict, predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('../data/songs_after_round_3_cleaning.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Lyrics Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_corpus = \"\"\n",
    "\n",
    "for l in list(songs['cleaned_lyrics']):\n",
    "    lyrics_corpus += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_list = lyrics_corpus.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_list = [s.replace(\"[\", \"\") for s in lyrics_list]\n",
    "lyrics_list = [s.replace(\"]\", \"\") for s in lyrics_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Probabilty Word Follows Another Word to Generate Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    occurence_count = Counter(List)\n",
    "    return occurence_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty = ['fuck','ass','shit','bitch','cunt','nigga','nigger','niggas','niggers','asshole','penis','bitches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lyrics(start_word, length):\n",
    "    \n",
    "    new_word = start_word\n",
    "    lyrics = start_word + ' '\n",
    "    \n",
    "    for i in range(length):\n",
    "        \n",
    "        following_words = []\n",
    "        \n",
    "        for i in range(len(lyrics_list)):\n",
    "            if (lyrics_list[i] == new_word) and (i != len(lyrics_list) -1):\n",
    "                following_words.append(lyrics_list[i+1])\n",
    "    \n",
    "        if len(set(following_words)) > 40:\n",
    "            fol = most_frequent(following_words)[randrange(8)][0]\n",
    "            if fol in dirty:\n",
    "                fol = most_frequent(following_words)[randrange(7)][0]\n",
    "            if fol in dirty:\n",
    "                fol = most_frequent(following_words)[randrange(7)][0]\n",
    "            lyrics += fol + \" \"\n",
    "            new_word = fol\n",
    "            \n",
    "        else:\n",
    "                lyrics += str(most_frequent(following_words)[0][0]) + \" \"\n",
    "                new_word = most_frequent(following_words)[0][0]\n",
    "                \n",
    "       \n",
    "            \n",
    "        \n",
    "    return(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'friends lets get your heart i aint never been a couple hoes and '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_lyrics('friends', 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a hundred on the world is the time that i cant believe me '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_lyrics('a', 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and a little more like the night to the same place for it '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_lyrics('and', 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he dont know i just like a lot for my way to my '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_lyrics('he', 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Song Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of first words in songs\n",
    "starter = ['i','im','you','dont','every',\n",
    "           'and','oh','yeah','youre','baby','so','she',\n",
    "           'he','they','this','well','we','hey','if','how','hold','wanting','just','medicine','yesterday',\n",
    "            'night','morning','sun','friend',\n",
    "            'first','time','anxiety','loving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_song(row_length):\n",
    "    l = []\n",
    "    for j in range(row_length):\n",
    "        l.append(create_lyrics(starter[randrange(len(starter))], randrange(5,15)))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morning raint and we aint even the night show i got it up i \n",
      "we could take it was there with a lot i know what it \n",
      "loving on you want me a hundred bands \n",
      "hey im a new age to my name you and the same time \n",
      "she gon have it i dont care for a little closer to do \n",
      "this is you and i aint \n",
      "i can you cant stop thinking about you got no i \n",
      "im the time and you got the way i was born to do \n",
      "sun rise and my head to be alright girl you know you and im not \n",
      "hold it on that youre gone i dont know i aint tryna make my \n",
      "and my own way too long so much time we are \n",
      "i cant keep the one i was there with \n",
      "they say it was some people dont wanna go to the top off \n",
      "first you know it up a lot for the time that we \n",
      "night i cant keep that i was just \n"
     ]
    }
   ],
   "source": [
    "for thing in write_song(15):\n",
    "    print(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morning im so i can be with my \n",
      "wanting my head and you got no i cant \n",
      "how i aint gotta say you want to do to \n",
      "first you and we gon make it to be my head to you got me \n",
      "hold on my head you and \n",
      "time and she dont even gotta be the night show up on your love \n",
      "youre gonna have you want it was \n"
     ]
    }
   ],
   "source": [
    "for thing in write_song(7):\n",
    "    print(thing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Pegasus Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "import io\n",
    "import seaborn as sb\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4335131"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lyrics_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_corpus[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'google/pegasus-xsum'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer.prepare_seq2seq_batch(lyrics_corpus[0:500], truncation=True, padding='longest', return_tensors='pt').to(torch_device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "print(tgt_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_song(row):\n",
    "    batch = tokenizer.prepare_seq2seq_batch(row['cleaned_lyrics'], truncation=True, padding='longest', return_tensors='pt').to(torch_device)\n",
    "    translated = model.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return str(tgt_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(songs['cleaned_lyrics'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs['pegasus'] = songs.apply(write_song, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making pegasus summary and appending into a list\n",
    "short_summary = []\n",
    "batch = tokenizer.prepare_seq2seq_batch(lyrics_corpus[0:30], truncation=True, padding='longest', return_tensors='pt').to(torch_device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "short_summary.append(str(tgt_text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
